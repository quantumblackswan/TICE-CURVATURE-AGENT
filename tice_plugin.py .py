"""
TICEPlugin: Symbolic Curvature Analytics Module
=================================================

This module defines the `TICEPlugin` class which encapsulates
computations for a symbolic curvature analytics system.  The
terminology used here (Δψ², τ, η, Λ, Ξχ, ΩΛ∞) comes from an
imagined physical model in which a learning agent maintains
observations of state changes (Δψ²), remembers historical
experience across a characteristic time window (τ) and is
subject to stochastic entropy noise (η).  The outputs of
interest—the curvature index (Λ), observer variance (Ξχ) and
entropy compression metric (ΩΛ∞)—provide continuous feedback
that can be used to steer optimisation algorithms or signal
external observers.

The `TICEPlugin` is implemented as a subclass of
``torch.nn.Module`` so that it can be dropped into any
PyTorch-based training pipeline.  The core methods are:

* ``compute_lambda_multi``: computes the curvature index
  Λ using Δψ², τ and η.  A larger state change increases
  Λ whereas longer memory horizons τ and higher entropy
  noise η suppress Λ.  An exponential decay on η is
  applied to ensure λ remains within a sensible range.
* ``compute_phi``: derives the observer variance Ξχ
  (here named φ internally) from the curvature index.  A
  hyperbolic tangent is used to project λ values onto a
  bounded interval.
* ``adjust_lambda``: takes an existing λ and adjusts it
  according to φ.  This adjustment introduces a dynamic
  feedback loop; positive φ amplifies λ while negative φ
  attenuates it.
* ``compute_omega``: computes ΩΛ∞, an entropy compression
  metric, from adjusted λ and φ.  This metric can be
  interpreted as the agent's ability to compress the
  information content of its experience relative to its
  perceived curvature and variance.

The module also exposes a convenience ``forward`` method
which performs all of these computations in sequence and
returns a tuple of (λ_adjusted, φ, ω).  See the example
below for how this might be used in a typical training loop.

Optionally, a REST API is provided using FastAPI.  When
deployed as a service, clients can POST JSON arrays of
``delta_psi_sq``, ``tau`` and ``eta`` and receive the
computed metrics in response.  This makes it easy to
integrate the module into SaaS environments or with
JavaScript-based front‑ends.  To start the API you would
run this file directly (``python tice_plugin.py``); see
``__main__`` below for details.

For advanced deployments, the code includes a skeleton
``ChainlinkOracle`` class to illustrate how external
validators or oracles might be integrated into the
computation.  In practice these would query an off‑chain
oracle network such as Chainlink, but here we provide
placeholder methods to demonstrate the interface.  This is
useful for scenarios where curvature analytics must be
auditable or verifiable on a blockchain.

Example
-------

Below is a contrived example showing how one could embed
``TICEPlugin`` into a simple PyTorch training loop.  The
``delta_psi_sq``/``tau``/``eta`` tensors are assumed to be
produced by the environment or previous computations.

```python
import torch
from torch.utils.data import DataLoader

from tice_plugin import TICEPlugin

# Create the plugin and an optimizer
plugin = TICEPlugin()
optimizer = torch.optim.Adam(plugin.parameters(), lr=1e-3)

# Suppose we have a dataset that yields (delta_psi_sq, tau, eta)
dataloader = DataLoader(...)

for epoch in range(num_epochs):
    for delta_psi_sq_batch, tau_batch, eta_batch in dataloader:
        # Forward pass through the plugin
        lambda_adj, phi, omega = plugin(delta_psi_sq_batch, tau_batch, eta_batch)

        # Compute some loss based on the outputs.  Here we
        # encourage the entropy compression metric omega to
        # remain small.  This is purely illustrative.
        loss = omega.pow(2).mean()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

Author
------

This module was generated by an AI assistant in 2025 as an
illustrative example.  It is not intended to model any
real physical process but can be adapted as needed.

"""

from __future__ import annotations

import math
from typing import Iterable, Optional, Sequence

try:
    import torch
except ImportError:
    raise ImportError("PyTorch is required to use TICEPlugin. Please install torch.")


class TICEPlugin(torch.nn.Module):
    """A PyTorch module implementing symbolic curvature analytics.

    Parameters
    ----------
    alpha : float, optional
        Scaling factor applied to the curvature index Λ.  A larger
        ``alpha`` amplifies the influence of Δψ² relative to τ
        and η.  Defaults to ``1.0``.
    beta : float, optional
        Offset added to the curvature index Λ.  This can be
        adjusted to calibrate the output range.  Defaults to ``0.0``.
    phi_gain : float, optional
        Multiplicative constant applied to λ when computing φ.  A
        higher ``phi_gain`` will saturate φ more quickly via the
        hyperbolic tangent.  Defaults to ``1.0``.
    lambda_feedback : float, optional
        Scaling factor for the feedback loop in ``adjust_lambda``.
        Positive values amplify λ for positive φ and attenuate for
        negative φ.  Defaults to ``1.0``.
    omega_gain : float, optional
        Scaling factor applied when computing the entropy
        compression metric ω.  Changing this value affects the
        sensitivity of ω to λ and φ.  Defaults to ``1.0``.

    Notes
    -----
    This module supports batched tensor inputs.  ``delta_psi_sq``,
    ``tau`` and ``eta`` should all be broadcastable to the same
    shape.  Gradients flow through all computations so these
    outputs can be optimised as part of a larger model.
    """

    def __init__(
        self,
        *,
        alpha: float = 1.0,
        beta: float = 0.0,
        phi_gain: float = 1.0,
        lambda_feedback: float = 1.0,
        omega_gain: float = 1.0,
    ) -> None:
        super().__init__()
        # Register parameters as buffers so they are part of the
        # state dict but not trained by default.  Users can set
        # requires_grad=True if they wish to fine‑tune them.
        self.alpha = torch.nn.Parameter(torch.tensor(alpha, dtype=torch.float32), requires_grad=False)
        self.beta = torch.nn.Parameter(torch.tensor(beta, dtype=torch.float32), requires_grad=False)
        self.phi_gain = torch.nn.Parameter(torch.tensor(phi_gain, dtype=torch.float32), requires_grad=False)
        self.lambda_feedback = torch.nn.Parameter(torch.tensor(lambda_feedback, dtype=torch.float32), requires_grad=False)
        self.omega_gain = torch.nn.Parameter(torch.tensor(omega_gain, dtype=torch.float32), requires_grad=False)

    def compute_lambda_multi(
        self,
        delta_psi_sq: torch.Tensor,
        tau: torch.Tensor,
        eta: torch.Tensor,
    ) -> torch.Tensor:
        """Compute the curvature index Λ for batched inputs.

        The curvature index captures how rapidly the agent's state is
        changing relative to its memory horizon and the noise
        environment.  It is defined by the heuristic formula:

        .. math::
            Λ = α \cdot \frac{Δψ^2}{τ + ε} \cdot \exp(-η) + β

        where :math:`α` and :math:`β` are scaling and offset
        parameters, respectively, and :math:`ε` is a small constant
        that prevents division by zero.

        Parameters
        ----------
        delta_psi_sq : torch.Tensor
            Squared state change (Δψ²).  Higher values indicate
            larger deviations between consecutive observations.
        tau : torch.Tensor
            Time memory (τ).  Represents the effective horizon over
            which the agent integrates past information.  Larger
            values reduce the curvature index because the agent
            smooths over longer histories.
        eta : torch.Tensor
            Entropy noise (η).  Models unpredictable variation in
            the environment; exponential decay ensures that higher
            noise dampens Λ.

        Returns
        -------
        torch.Tensor
            Tensor of curvature indices Λ with the same shape as the
            broadcasted inputs.
        """
        # Ensure numerical stability: add a small epsilon to tau
        eps = 1e-8
        # Compute base curvature index
        base = delta_psi_sq / (tau + eps)
        # Apply noise decay
        decayed = base * torch.exp(-eta)
        # Apply scaling and offset
        lambda_multi = self.alpha * decayed + self.beta
        return lambda_multi

    def compute_phi(self, lambda_values: torch.Tensor) -> torch.Tensor:
        """Compute the observer variance Ξχ (here denoted φ) from λ.

        The observer variance provides a bounded measure of how
        volatile the curvature index is relative to its expected
        range.  We use the hyperbolic tangent to limit the output
        between -1 and 1.  The gain parameter ``phi_gain`` controls
        the steepness of this non‑linear transformation.

        Parameters
        ----------
        lambda_values : torch.Tensor
            Curvature indices Λ from which to compute φ.

        Returns
        -------
        torch.Tensor
            Tensor of observer variance values Ξχ (φ).
        """
        return torch.tanh(self.phi_gain * lambda_values)

    def adjust_lambda(
        self,
        lambda_values: torch.Tensor,
        phi: torch.Tensor,
    ) -> torch.Tensor:
        """Apply a feedback adjustment to λ based on φ.

        The adjustment modifies each λ according to

        .. math::
            \Lambda_{\text{adj}} = Λ \cdot (1 + \gamma \cdot φ)

        where ``gamma`` is ``lambda_feedback``.  Positive φ
        amplifies λ, negative φ diminishes λ, and φ near zero
        leaves λ unchanged.  The feedback loop can be tuned by
        adjusting ``gamma``.

        Parameters
        ----------
        lambda_values : torch.Tensor
            Unadjusted curvature indices Λ.
        phi : torch.Tensor
            Observer variance values φ derived from Λ.

        Returns
        -------
        torch.Tensor
            Adjusted curvature indices Λ_adj.
        """
        return lambda_values * (1.0 + self.lambda_feedback * phi)

    def compute_omega(
        self,
        lambda_adj: torch.Tensor,
        phi: torch.Tensor,
    ) -> torch.Tensor:
        """Compute the entropy compression metric ΩΛ∞ from λ_adj and φ.

        The entropy compression metric measures how effectively the
        agent can compress its experience, taking into account the
        adjusted curvature and observer variance.  We use the
        following formula:

        .. math::
            ΩΛ∞ = ω_{\text{gain}} \times \frac{Λ_{\text{adj}}}{1 + |φ|}

        where ``omega_gain`` scales the result.  This ensures that
        ω diminishes when observer variance grows (i.e., high
        uncertainty reduces the compression ability).

        Parameters
        ----------
        lambda_adj : torch.Tensor
            Adjusted curvature indices Λ_adj.
        phi : torch.Tensor
            Observer variance values φ.

        Returns
        -------
        torch.Tensor
            The entropy compression metric ΩΛ∞.
        """
        return self.omega_gain * lambda_adj / (1.0 + torch.abs(phi))

    def forward(
        self,
        delta_psi_sq: torch.Tensor,
        tau: torch.Tensor,
        eta: torch.Tensor,
    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """Compute Λ_adj, φ and ΩΛ∞ in a single pass.

        This convenience method calls ``compute_lambda_multi``,
        ``compute_phi``, ``adjust_lambda`` and ``compute_omega``
        sequentially.  It is especially useful in training loops
        where all outputs are needed at once.

        Parameters
        ----------
        delta_psi_sq : torch.Tensor
            Squared state change values Δψ².
        tau : torch.Tensor
            Time memory values τ.
        eta : torch.Tensor
            Entropy noise values η.

        Returns
        -------
        tuple of torch.Tensor
            ``(lambda_adj, phi, omega)`` where each element has
            shape broadcastable to the inputs.
        """
        lambda_raw = self.compute_lambda_multi(delta_psi_sq, tau, eta)
        phi = self.compute_phi(lambda_raw)
        lambda_adj = self.adjust_lambda(lambda_raw, phi)
        omega = self.compute_omega(lambda_adj, phi)
        return lambda_adj, phi, omega


class ChainlinkOracle:
    """Skeleton of a Chainlink oracle integration.

    In decentralised applications it is often desirable to
    validate data or fetch external parameters from an oracle
    network.  Chainlink is a popular choice for this.  This
    class outlines how one might build such an integration.

    The methods here are placeholders; in a real implementation
    they would perform on‑chain or off‑chain calls to a Chainlink
    node or a blockchain smart contract.  These calls would
    typically involve asynchronous communication and cryptographic
    signatures.  For demonstration purposes we return fixed
    values.
    """

    def __init__(self, oracle_url: str = "http://chainlink.oracle", api_key: Optional[str] = None) -> None:
        self.oracle_url = oracle_url
        self.api_key = api_key

    def fetch_validation_threshold(self, metric_name: str) -> float:
        """Fetch a threshold value for a given metric from the oracle.

        In a realistic scenario this would perform an HTTP request or
        smart contract call to retrieve a threshold used to validate
        curvature metrics.  For example, a blockchain contract might
        publish a maximum allowable λ to ensure model stability.

        Parameters
        ----------
        metric_name : str
            Name of the metric to fetch (e.g., ``"lambda"`` or
            ``"omega"``).

        Returns
        -------
        float
            A threshold value for the requested metric.
        """
        # Placeholder implementation: return a constant threshold
        if metric_name.lower() == "lambda":
            return 10.0
        elif metric_name.lower() == "omega":
            return 5.0
        else:
            return 1.0

    def validate_metric(self, value: float, threshold: float) -> bool:
        """Validate a computed metric against a threshold.

        Parameters
        ----------
        value : float
            The computed metric value.
        threshold : float
            Threshold fetched from the oracle.

        Returns
        -------
        bool
            ``True`` if ``value`` is within acceptable bounds,
            ``False`` otherwise.
        """
        return value <= threshold


# Optional REST API using FastAPI.  This section is executed only
# when the module is run directly (``python tice_plugin.py``).
try:
    from fastapi import FastAPI
    from pydantic import BaseModel
    import uvicorn

    class ComputeRequest(BaseModel):
        """Pydantic model for incoming compute requests.

        Each field may be either a single float/int or a list of
        floats/ints.  Lists must have the same length; scalars
        broadcast naturally.
        """
        delta_psi_sq: Sequence[float] | float
        tau: Sequence[float] | float
        eta: Sequence[float] | float

    class ComputeResponse(BaseModel):
        """Model for the API response containing curvature metrics."""
        lambda_adj: list[float]
        phi: list[float]
        omega: list[float]

    app = FastAPI(title="TICEPlugin API", description="Compute curvature analytics via REST")

    # Instantiate a global plugin for repeated calls.  It could be
    # swapped out with a stateful version if needed.
    _plugin_instance = TICEPlugin()

    def _ensure_tensor(x: Sequence[float] | float) -> torch.Tensor:
        """Convert a scalar or sequence into a 1D float tensor."""
        if isinstance(x, (int, float)):
            return torch.tensor([float(x)], dtype=torch.float32)
        else:
            return torch.tensor(list(x), dtype=torch.float32)

    @app.post("/compute", response_model=ComputeResponse)
    async def compute_endpoint(req: ComputeRequest) -> ComputeResponse:
        """Compute curvature metrics for the provided inputs.

        The endpoint accepts JSON with ``delta_psi_sq``, ``tau`` and
        ``eta`` as either scalars or lists.  It returns the adjusted
        curvature index λ_adj, observer variance φ and entropy
        compression metric ω.
        """
        delta_psi_sq_t = _ensure_tensor(req.delta_psi_sq)
        tau_t = _ensure_tensor(req.tau)
        eta_t = _ensure_tensor(req.eta)
        # Broadcast inputs
        lambda_adj, phi, omega = _plugin_instance(delta_psi_sq_t, tau_t, eta_t)
        # Flatten to Python lists for JSON serialisation
        return ComputeResponse(
            lambda_adj=lambda_adj.detach().cpu().numpy().tolist(),
            phi=phi.detach().cpu().numpy().tolist(),
            omega=omega.detach().cpu().numpy().tolist(),
        )

    def run_api(host: str = "0.0.0.0", port: int = 8000) -> None:
        """Run the FastAPI application using Uvicorn.

        This helper function starts an ASGI server.  It is intended
        for demonstration; in production you might configure
        additional settings such as SSL, logging or workers.
        """
        uvicorn.run(app, host=host, port=port)
except ImportError:
    # FastAPI is optional; if it's not available the API will not
    # be defined.  Users can still import TICEPlugin.
    app = None  # type: ignore
    def run_api(*args, **kwargs) -> None:
        raise RuntimeError("FastAPI is not installed; install fastapi and uvicorn to run the API.")


if __name__ == "__main__":
    # When run as a script, start the REST API if available.
    try:
        print("Starting TICEPlugin API...")
        run_api()
    except RuntimeError as e:
        print(e)