"""
TICEPlugin: Symbolic Curvature Analytics Module
=================================================

This module defines the `TICEPlugin` class which encapsulates
computations for a symbolic curvature analytics system.  The
terminology used here (Δψ², τ, η, Λ, Ξχ, ΩΛ∞) comes from an
imagined physical model in which a learning agent maintains
observations of state changes (Δψ²), remembers historical
experience across a characteristic time window (τ) and is
subject to stochastic entropy noise (η).  The outputs of
interest—the curvature index (Λ), observer variance (Ξχ) and
entropy compression metric (ΩΛ∞)—provide continuous feedback
that can be used to steer optimisation algorithms or signal
external observers.

The `TICEPlugin` is implemented as a subclass of
``torch.nn.Module`` so that it can be dropped into any
PyTorch-based training pipeline.  The core methods are:

* ``compute_lambda_multi``: computes the curvature index
  Λ using Δψ², τ and η.  A larger state change increases
  Λ whereas longer memory horizons τ and higher entropy
  noise η suppress Λ.  An exponential decay on η is
  applied to ensure λ remains within a sensible range.
* ``compute_phi``: derives the observer variance Ξχ
  (here named φ internally) from the curvature index.  A
  hyperbolic tangent is used to project λ values onto a
  bounded interval.
* ``adjust_lambda``: takes an existing λ and adjusts it
  according to φ.  This adjustment introduces a dynamic
  feedback loop; positive φ amplifies λ while negative φ
  attenuates it.
* ``compute_omega``: computes ΩΛ∞, an entropy compression
  metric, from adjusted λ and φ.  This metric can be
  interpreted as the agent's ability to compress the
  information content of its experience relative to its
  perceived curvature and variance.

The module also exposes a convenience ``forward`` method
which performs all of these computations in sequence and
returns a tuple of (λ_adjusted, φ, ω).  See the example
below for how this might be used in a typical training loop.

Optionally, a REST API is provided using FastAPI.  When
deployed as a service, clients can POST JSON arrays of
``delta_psi_sq``, ``tau`` and ``eta`` and receive the
computed metrics in response.  This makes it easy to
integrate the module into SaaS environments or with
JavaScript-based front‑ends.  To start the API you would
run this file directly (``python tice_plugin.py``); see
``__main__`` below for details.

For advanced deployments, the code includes a skeleton
``ChainlinkOracle`` class to illustrate how external
validators or oracles might be integrated into the
computation.  In practice these would query an off‑chain
oracle network such as Chainlink, but here we provide
placeholder methods to demonstrate the interface.  This is
useful for scenarios where curvature analytics must be
auditable or verifiable on a blockchain.

Example
-------

Below is a contrived example showing how one could embed
``TICEPlugin`` into a simple PyTorch training loop.  The
``delta_psi_sq``/``tau``/``eta`` tensors are assumed to be
produced by the environment or previous computations.

```python
import torch
from torch.utils.data import DataLoader

from tice_plugin import TICEPlugin

# Create the plugin and an optimizer
plugin = TICEPlugin()
optimizer = torch.optim.Adam(plugin.parameters(), lr=1e-3)

# Suppose we have a dataset that yields (delta_psi_sq, tau, eta)
dataloader = DataLoader(...)

for epoch in range(num_epochs):
    for delta_psi_sq_batch, tau_batch, eta_batch in dataloader:
        # Forward pass through the plugin
        lambda_adj, phi, omega = plugin(delta_psi_sq_batch, tau_batch, eta_batch)

        # Compute some loss based on the outputs.  Here we
        # encourage the entropy compression metric omega to
        # remain small.  This is purely illustrative.
        loss = omega.pow(2).mean()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

Author
------

This module was generated by an AI assistant in 2025 as an
illustrative example.  It is not intended to model any
real physical process but can be adapted as needed.

"""

from __future__ import annotations

import math
from typing import Iterable, Optional, Sequence

try:
    import torch
except ImportError:
    raise ImportError("PyTorch is required to use TICEPlugin. Please install torch.")


class TICEPlugin(torch.nn.Module):
    """A PyTorch module implementing symbolic curvature analytics with internal memory.

    This class has been expanded to address several limitations of
    the original implementation.  Notably, it now maintains an
    internal ring buffer of recent state change measurements so
    that it can compute curvature even when external Δψ²/τ/η are
    not provided.  It also records every computed metric along
    with timestamps in a history buffer.  This history can be
    queried through ``log_metrics``/``get_history`` and used for
    trust‑trace audits, plotting or feeding into larger AGI
    memory graphs.

    Parameters
    ----------
    alpha : float, optional
        Scaling factor applied to the curvature index Λ.  A larger
        ``alpha`` amplifies the influence of Δψ² relative to τ and
        η.  Defaults to ``1.0``.
    beta : float, optional
        Offset added to the curvature index Λ.  This can be
        adjusted to calibrate the output range.  Defaults to ``0.0``.
    phi_gain : float, optional
        Multiplicative constant applied to λ when computing φ.  A
        higher ``phi_gain`` will saturate φ more quickly via the
        hyperbolic tangent.  Defaults to ``1.0``.
    lambda_feedback : float, optional
        Scaling factor for the feedback loop in ``adjust_lambda``.
        Positive values amplify λ for positive φ and attenuate for
        negative φ.  Defaults to ``1.0``.
    omega_gain : float, optional
        Scaling factor applied when computing the entropy
        compression metric ω.  Changing this value affects the
        sensitivity of ω to λ and φ.  Defaults to ``1.0``.
    buffer_size : int, optional
        Number of recent samples stored in the internal ring buffer.
        When the buffer is full, the oldest entry is dropped.  This
        enables the module to compute moving averages of Δψ², τ and
        η when explicit inputs are not supplied.  Defaults to ``100``.
    enable_history : bool, optional
        Whether to record a detailed history of each call to
        ``forward``.  When enabled, each invocation logs the
        computed Λ, φ and ω along with the raw inputs and a
        timestamp.  This history can later be retrieved via
        ``get_history`` for analysis or audit.  Defaults to ``True``.

    Notes
    -----
    The module supports batched tensor inputs.  ``delta_psi_sq``,
    ``tau`` and ``eta`` should all be broadcastable to the same
    shape.  Gradients flow through all computations so these
    outputs can be optimised as part of a larger model.  If any
    of these arguments are ``None``, the module will instead
    compute their values from its internal buffer using simple
    exponential moving averages.  This allows the plugin to be
    self‑updating over time.
    """

    def __init__(
        self,
        *,
        alpha: float = 1.0,
        beta: float = 0.0,
        phi_gain: float = 1.0,
        lambda_feedback: float = 1.0,
        omega_gain: float = 1.0,
        buffer_size: int = 100,
        enable_history: bool = True,
    ) -> None:
        super().__init__()
        # Register parameters as buffers so they are part of the
        # state dict but not trained by default.  Users can set
        # requires_grad=True if they wish to fine‑tune them.
        self.alpha = torch.nn.Parameter(torch.tensor(alpha, dtype=torch.float32), requires_grad=False)
        self.beta = torch.nn.Parameter(torch.tensor(beta, dtype=torch.float32), requires_grad=False)
        self.phi_gain = torch.nn.Parameter(torch.tensor(phi_gain, dtype=torch.float32), requires_grad=False)
        self.lambda_feedback = torch.nn.Parameter(torch.tensor(lambda_feedback, dtype=torch.float32), requires_grad=False)
        self.omega_gain = torch.nn.Parameter(torch.tensor(omega_gain, dtype=torch.float32), requires_grad=False)

        # Internal ring buffers for state variables and noise.  These
        # allow the module to maintain a history of its own
        # observations and compute moving averages when no explicit
        # inputs are provided.
        self.buffer_size = buffer_size
        self.delta_history: list[float] = []
        self.tau_history: list[float] = []
        self.eta_history: list[float] = []
        # History of computed metrics
        self.enable_history = enable_history
        self.history: list[dict[str, float]] = []
        # Last timestamp used for computing τ automatically
        self._last_timestamp: Optional[float] = None

    def compute_lambda_multi(
        self,
        delta_psi_sq: torch.Tensor,
        tau: torch.Tensor,
        eta: torch.Tensor,
    ) -> torch.Tensor:
        """Compute the curvature index Λ for batched inputs.

        The curvature index captures how rapidly the agent's state is
        changing relative to its memory horizon and the noise
        environment.  It is defined by the heuristic formula:

        .. math::
            Λ = α \cdot \frac{Δψ^2}{τ + ε} \cdot \exp(-η) + β

        where :math:`α` and :math:`β` are scaling and offset
        parameters, respectively, and :math:`ε` is a small constant
        that prevents division by zero.

        Parameters
        ----------
        delta_psi_sq : torch.Tensor
            Squared state change (Δψ²).  Higher values indicate
            larger deviations between consecutive observations.
        tau : torch.Tensor
            Time memory (τ).  Represents the effective horizon over
            which the agent integrates past information.  Larger
            values reduce the curvature index because the agent
            smooths over longer histories.
        eta : torch.Tensor
            Entropy noise (η).  Models unpredictable variation in
            the environment; exponential decay ensures that higher
            noise dampens Λ.

        Returns
        -------
        torch.Tensor
            Tensor of curvature indices Λ with the same shape as the
            broadcasted inputs.
        """
        # Ensure numerical stability: add a small epsilon to tau
        eps = 1e-8
        # Compute base curvature index
        base = delta_psi_sq / (tau + eps)
        # Apply noise decay
        decayed = base * torch.exp(-eta)
        # Apply scaling and offset
        lambda_multi = self.alpha * decayed + self.beta
        return lambda_multi

    def compute_phi(self, lambda_values: torch.Tensor) -> torch.Tensor:
        """Compute the observer variance Ξχ (here denoted φ) from λ.

        The observer variance provides a bounded measure of how
        volatile the curvature index is relative to its expected
        range.  We use the hyperbolic tangent to limit the output
        between -1 and 1.  The gain parameter ``phi_gain`` controls
        the steepness of this non‑linear transformation.

        Parameters
        ----------
        lambda_values : torch.Tensor
            Curvature indices Λ from which to compute φ.

        Returns
        -------
        torch.Tensor
            Tensor of observer variance values Ξχ (φ).
        """
        return torch.tanh(self.phi_gain * lambda_values)

    def adjust_lambda(
        self,
        lambda_values: torch.Tensor,
        phi: torch.Tensor,
    ) -> torch.Tensor:
        """Apply a feedback adjustment to λ based on φ.

        The adjustment modifies each λ according to

        .. math::
            \Lambda_{\text{adj}} = Λ \cdot (1 + \gamma \cdot φ)

        where ``gamma`` is ``lambda_feedback``.  Positive φ
        amplifies λ, negative φ diminishes λ, and φ near zero
        leaves λ unchanged.  The feedback loop can be tuned by
        adjusting ``gamma``.

        Parameters
        ----------
        lambda_values : torch.Tensor
            Unadjusted curvature indices Λ.
        phi : torch.Tensor
            Observer variance values φ derived from Λ.

        Returns
        -------
        torch.Tensor
            Adjusted curvature indices Λ_adj.
        """
        return lambda_values * (1.0 + self.lambda_feedback * phi)

    def compute_omega(
        self,
        lambda_adj: torch.Tensor,
        phi: torch.Tensor,
    ) -> torch.Tensor:
        """Compute the entropy compression metric ΩΛ∞ from λ_adj and φ.

        The entropy compression metric measures how effectively the
        agent can compress its experience, taking into account the
        adjusted curvature and observer variance.  We use the
        following formula:

        .. math::
            ΩΛ∞ = ω_{\text{gain}} \times \frac{Λ_{\text{adj}}}{1 + |φ|}

        where ``omega_gain`` scales the result.  This ensures that
        ω diminishes when observer variance grows (i.e., high
        uncertainty reduces the compression ability).

        Parameters
        ----------
        lambda_adj : torch.Tensor
            Adjusted curvature indices Λ_adj.
        phi : torch.Tensor
            Observer variance values φ.

        Returns
        -------
        torch.Tensor
            The entropy compression metric ΩΛ∞.
        """
        return self.omega_gain * lambda_adj / (1.0 + torch.abs(phi))

    def forward(
        self,
        delta_psi_sq: Optional[torch.Tensor] = None,
        tau: Optional[torch.Tensor] = None,
        eta: Optional[torch.Tensor] = None,
    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """Compute Λ_adj, φ and ΩΛ∞ in a single pass.

        This convenience method calls ``compute_lambda_multi``,
        ``compute_phi``, ``adjust_lambda`` and ``compute_omega``
        sequentially.  It is especially useful in training loops
        where all outputs are needed at once.

        Parameters
        ----------
        delta_psi_sq : torch.Tensor or None
            Squared state change values Δψ².  If ``None``, the value
            is estimated from the internal buffer using an
            exponential moving average of recent history.
        tau : torch.Tensor or None
            Time memory values τ.  If ``None``, it is computed as
            the difference between the current timestamp and the
            previous call's timestamp.  When unavailable (e.g.
            first call) a default value of 1.0 is used.
        eta : torch.Tensor or None
            Entropy noise values η.  If ``None``, the module
            computes an exponential moving average of past η values
            from the buffer or uses a default of 0.

        Returns
        -------
        tuple of torch.Tensor
            ``(lambda_adj, phi, omega)`` where each element has
            shape broadcastable to the inputs.
        """
        import time

        # If any input is None, compute defaults from internal
        # history.  A simple exponential moving average (EMA) is used
        # for delta_psi_sq and eta; τ is derived from timestamps.
        def ema(values: list[float], alpha: float = 0.1, default: float = 0.0) -> float:
            if not values:
                return default
            avg = values[0]
            for v in values[1:]:
                avg = alpha * v + (1 - alpha) * avg
            return avg

        # Determine τ automatically if not provided
        current_time = time.time()
        if tau is None:
            if self._last_timestamp is None:
                tau_estimate = torch.tensor([1.0], dtype=torch.float32)
            else:
                dt = current_time - self._last_timestamp
                tau_estimate = torch.tensor([float(max(dt, 1e-3))], dtype=torch.float32)
            tau = tau_estimate
        # Determine delta_psi_sq automatically if not provided
        if delta_psi_sq is None:
            delta_est = ema(self.delta_history, default=0.0)
            delta_psi_sq = torch.tensor([delta_est], dtype=torch.float32)
        # Determine eta automatically if not provided
        if eta is None:
            eta_est = ema(self.eta_history, default=0.0)
            eta = torch.tensor([eta_est], dtype=torch.float32)

        # Convert scalars to tensors if necessary
        if not isinstance(delta_psi_sq, torch.Tensor):
            delta_psi_sq = torch.tensor(delta_psi_sq, dtype=torch.float32)
        if not isinstance(tau, torch.Tensor):
            tau = torch.tensor(tau, dtype=torch.float32)
        if not isinstance(eta, torch.Tensor):
            eta = torch.tensor(eta, dtype=torch.float32)

        # Compute the raw metrics
        lambda_raw = self.compute_lambda_multi(delta_psi_sq, tau, eta)
        phi = self.compute_phi(lambda_raw)
        lambda_adj = self.adjust_lambda(lambda_raw, phi)
        omega = self.compute_omega(lambda_adj, phi)

        # Update internal ring buffer and history
        self.update_buffer(delta_psi_sq.detach().cpu(), tau.detach().cpu(), eta.detach().cpu())
        if self.enable_history:
            self.log_metrics(
                delta_psi_sq=float(delta_psi_sq.mean()),
                tau=float(tau.mean()),
                eta=float(eta.mean()),
                lambda_raw=float(lambda_raw.mean()),
                lambda_adj=float(lambda_adj.mean()),
                phi=float(phi.mean()),
                omega=float(omega.mean()),
                timestamp=current_time,
            )
        # Update timestamp for τ estimation on next call
        self._last_timestamp = current_time
        return lambda_adj, phi, omega

    # ------------------------------------------------------------------
    # Internal memory and history management
    # ------------------------------------------------------------------
    def update_buffer(self, delta_psi_sq: torch.Tensor, tau: torch.Tensor, eta: torch.Tensor) -> None:
        """Append new observations to the internal ring buffer.

        When the buffer exceeds ``buffer_size``, the oldest
        observations are discarded.  This method is called
        automatically from ``forward`` whenever new data is
        processed.

        Parameters
        ----------
        delta_psi_sq : torch.Tensor
            Latest squared state change values.
        tau : torch.Tensor
            Latest time memory values.
        eta : torch.Tensor
            Latest entropy noise values.
        """
        def append_and_trim(lst: list[float], value: float) -> None:
            lst.append(float(value))
            if len(lst) > self.buffer_size:
                del lst[0]

        append_and_trim(self.delta_history, float(delta_psi_sq.mean()))
        append_and_trim(self.tau_history, float(tau.mean()))
        append_and_trim(self.eta_history, float(eta.mean()))

    def log_metrics(
        self,
        *,
        delta_psi_sq: float,
        tau: float,
        eta: float,
        lambda_raw: float,
        lambda_adj: float,
        phi: float,
        omega: float,
        timestamp: float,
    ) -> None:
        """Record a new entry in the history buffer.

        Each entry includes the raw inputs, computed metrics and a
        timestamp.  Users may call ``get_history`` to access this
        data later.  This method is typically invoked from
        ``forward``, but can also be called manually.
        """
        self.history.append({
            "timestamp": timestamp,
            "delta_psi_sq": delta_psi_sq,
            "tau": tau,
            "eta": eta,
            "lambda_raw": lambda_raw,
            "lambda_adj": lambda_adj,
            "phi": phi,
            "omega": omega,
        })

    def get_history(self) -> list[dict[str, float]]:
        """Return the internal history buffer.

        Returns
        -------
        list of dict
            List of history records ordered from oldest to newest.
            Each record contains the keys
            ``timestamp``, ``delta_psi_sq``, ``tau``, ``eta``,
            ``lambda_raw``, ``lambda_adj``, ``phi`` and ``omega``.
        """
        return list(self.history)

    def clear_history(self) -> None:
        """Erase the history buffer.  Useful for resetting logs."""
        self.history.clear()

    # ------------------------------------------------------------------
    # Self‑reflection and validation
    # ------------------------------------------------------------------
    def validate(self, lambda_adj: torch.Tensor, phi: torch.Tensor) -> bool:
        """Check whether computed metrics fall within safe bounds.

        This simple validator ensures that adjusted λ values and φ
        values do not saturate beyond plausible ranges.  If λ
        exceeds ten times the mean of past λ values or if |φ| > 0.99
        (saturation), the method returns ``False`` and warns the
        caller.  The thresholds can be tuned or replaced with more
        sophisticated symbolic coherence checks.

        Parameters
        ----------
        lambda_adj : torch.Tensor
            Adjusted curvature indices from the most recent call.
        phi : torch.Tensor
            Observer variance values from the most recent call.

        Returns
        -------
        bool
            ``True`` if the metrics are within acceptable bounds;
            ``False`` otherwise.
        """
        # Compute mean of past lambda values for context
        past_lambda_mean = 0.0
        if self.history:
            past_lambda_mean = float(sum(h["lambda_adj"] for h in self.history) / len(self.history))
        # Saturation checks
        lambda_excess = lambda_adj.detach().cpu().abs().max() > 10.0 * (past_lambda_mean + 1e-6)
        phi_saturation = phi.detach().cpu().abs().max() > 0.99
        return not (lambda_excess or phi_saturation)

    def criticize(self, lambda_adj: torch.Tensor, phi: torch.Tensor) -> str:
        """Provide a textual critique based on current metrics.

        If metrics are out of bounds, the critique will indicate
        possible causes such as excessive curvature or observer
        saturation.  Otherwise, it affirms that the metrics are
        within expected ranges.

        Parameters
        ----------
        lambda_adj : torch.Tensor
            Adjusted curvature indices.
        phi : torch.Tensor
            Observer variance values.

        Returns
        -------
        str
            A message describing the health of the system.
        """
        is_valid = self.validate(lambda_adj, phi)
        if is_valid:
            return "Metrics are within acceptable bounds."
        messages: list[str] = []
        past_lambda_mean = 0.0
        if self.history:
            past_lambda_mean = float(sum(h["lambda_adj"] for h in self.history) / len(self.history))
        if lambda_adj.detach().cpu().abs().max() > 10.0 * (past_lambda_mean + 1e-6):
            messages.append("Λ_adj has diverged beyond 10× the historical mean. Consider reducing Δψ² or τ.")
        if phi.detach().cpu().abs().max() > 0.99:
            messages.append("φ is saturated near ±1, indicating observer variance instability.")
        return " ".join(messages)

    # ------------------------------------------------------------------
    # Advanced analytics
    # ------------------------------------------------------------------
    def curvature_acceleration(self) -> Optional[float]:
        """Compute the second derivative of curvature (Δ²Ψ) over time.

        This method estimates the acceleration of the curvature index
        by taking a finite difference of λ_adj values stored in the
        history buffer.  It returns ``None`` if fewer than three
        history records exist.  Positive acceleration indicates
        increasing curvature divergence, whereas negative values
        suggest a deceleration.

        Returns
        -------
        float or None
            The estimated curvature acceleration, or ``None`` if
            insufficient history is available.
        """
        if len(self.history) < 3:
            return None
        # Use central difference on the most recent three entries
        l1 = self.history[-3]["lambda_adj"]
        l2 = self.history[-2]["lambda_adj"]
        l3 = self.history[-1]["lambda_adj"]
        t1 = self.history[-3]["timestamp"]
        t2 = self.history[-2]["timestamp"]
        t3 = self.history[-1]["timestamp"]
        # First derivatives
        v1 = (l2 - l1) / max(t2 - t1, 1e-6)
        v2 = (l3 - l2) / max(t3 - t2, 1e-6)
        # Acceleration (second derivative)
        acc = (v2 - v1) / max(t3 - t1, 1e-6)
        return acc

    def ricci_flow_graph(self) -> Optional["networkx.Graph"]:
        """Generate a Ricci flow graph from the φ matrix using NetworkX.

        The observer variance φ can be interpreted as a weighted
        adjacency matrix between nodes representing different
        observational dimensions.  This method constructs a simple
        undirected graph where each node is a dimension of φ and
        edge weights are set to the absolute differences between
        successive φ values in the history.  It then runs a basic
        Ricci flow approximation by computing edge betweenness
        centrality using NetworkX.  The resulting graph object can
        be further analysed or visualised externally.

        Returns
        -------
        networkx.Graph or None
            A graph representing the Ricci flow over the observed
            variance dimensions, or ``None`` if fewer than two
            history entries exist or NetworkX is unavailable.
        """
        try:
            import networkx as nx
        except ImportError:
            return None
        if len(self.history) < 2:
            return None
        # Build nodes: each dimension of φ is a node.  Since φ is
        # scalar in this implementation, create a single node graph.
        # To illustrate, we still create a graph with one node and a
        # self‑loop weighted by variance differences.
        G = nx.Graph()
        G.add_node(0)
        # Edge weight is absolute difference between successive φ
        phi_prev = self.history[-2]["phi"]
        phi_curr = self.history[-1]["phi"]
        weight = abs(phi_curr - phi_prev)
        # Add a self‑loop to represent curvature along the same
        # dimension; in a real multi‑dimensional setting there would
        # be edges between different dimensions.
        G.add_edge(0, 0, weight=weight)
        # Compute edge betweenness centrality as a proxy for Ricci flow
        _ = nx.edge_betweenness_centrality(G, weight="weight")
        return G


class ChainlinkOracle:
    """Skeleton of a Chainlink oracle integration.

    In decentralised applications it is often desirable to
    validate data or fetch external parameters from an oracle
    network.  Chainlink is a popular choice for this.  This
    class outlines how one might build such an integration.

    The methods here are placeholders; in a real implementation
    they would perform on‑chain or off‑chain calls to a Chainlink
    node or a blockchain smart contract.  These calls would
    typically involve asynchronous communication and cryptographic
    signatures.  For demonstration purposes we return fixed
    values.
    """

    def __init__(self, oracle_url: str = "http://chainlink.oracle", api_key: Optional[str] = None) -> None:
        self.oracle_url = oracle_url
        self.api_key = api_key
        # Configure retry attempts for asynchronous threshold fetches
        self.max_retries: int = 3

    async def fetch_validation_threshold(self, metric_name: str) -> float:
        """Asynchronously fetch a threshold value for a given metric from the oracle.

        In a realistic scenario this would perform an HTTP request or
        smart contract call to retrieve a threshold used to validate
        curvature metrics.  For example, a blockchain contract might
        publish a maximum allowable λ to ensure model stability.  This
        method is asynchronous to reflect network latency and it
        implements a simple retry mechanism: it will attempt the
        request up to ``self.max_retries`` times, waiting briefly
        between attempts.  In this placeholder implementation
        deterministic constants are returned.

        Parameters
        ----------
        metric_name : str
            Name of the metric to fetch (e.g., ``"lambda"`` or
            ``"omega"``).

        Returns
        -------
        float
            A threshold value for the requested metric.
        """
        import asyncio
        for attempt in range(self.max_retries):
            try:
                # Simulate network delay
                await asyncio.sleep(0.05 * (attempt + 1))
                # In a real implementation, perform HTTP or smart contract call
                if metric_name.lower() == "lambda":
                    return 10.0
                elif metric_name.lower() == "omega":
                    return 5.0
                else:
                    return 1.0
            except Exception:
                # Last attempt raises; others retry with backoff
                if attempt == self.max_retries - 1:
                    raise
                await asyncio.sleep(0.1 * (attempt + 1))

    def validate_metric(self, value: float, threshold: float) -> bool:
        """Validate a computed metric against a threshold.

        Parameters
        ----------
        value : float
            The computed metric value.
        threshold : float
            Threshold fetched from the oracle.

        Returns
        -------
        bool
            ``True`` if ``value`` is within acceptable bounds,
            ``False`` otherwise.
        """
        return value <= threshold


# Optional REST API using FastAPI.  This section is executed only
# when the module is run directly (``python tice_plugin.py``).
try:
    from fastapi import FastAPI
    from pydantic import BaseModel
    import uvicorn

    class ComputeRequest(BaseModel):
        """Pydantic model for incoming compute requests.

        Each field may be either a single float/int or a list of
        floats/ints.  Lists must have the same length; scalars
        broadcast naturally.
        """
        delta_psi_sq: Sequence[float] | float
        tau: Sequence[float] | float
        eta: Sequence[float] | float

    class ComputeResponse(BaseModel):
        """Model for the API response containing curvature metrics."""
        lambda_adj: list[float]
        phi: list[float]
        omega: list[float]

    app = FastAPI(title="TICEPlugin API", description="Compute curvature analytics via REST")

    # Instantiate a global plugin for repeated calls.  It could be
    # swapped out with a stateful version if needed.
    _plugin_instance = TICEPlugin()

    def _ensure_tensor(x: Sequence[float] | float) -> torch.Tensor:
        """Convert a scalar or sequence into a 1D float tensor."""
        if isinstance(x, (int, float)):
            return torch.tensor([float(x)], dtype=torch.float32)
        else:
            return torch.tensor(list(x), dtype=torch.float32)

    @app.post("/compute", response_model=ComputeResponse)
    async def compute_endpoint(req: ComputeRequest) -> ComputeResponse:
        """Compute curvature metrics for the provided inputs.

        The endpoint accepts JSON with ``delta_psi_sq``, ``tau`` and
        ``eta`` as either scalars or lists.  It returns the adjusted
        curvature index λ_adj, observer variance φ and entropy
        compression metric ω.  Computed metrics are logged in the
        plugin's internal history buffer.  A self‑validation check
        occurs to ensure outputs remain within safe bounds; if
        invalid, an HTTP 400 error is raised.
        """
        delta_psi_sq_t = _ensure_tensor(req.delta_psi_sq)
        tau_t = _ensure_tensor(req.tau)
        eta_t = _ensure_tensor(req.eta)
        # Forward pass through the plugin
        lambda_adj, phi, omega = _plugin_instance(delta_psi_sq_t, tau_t, eta_t)
        # Validate and criticise metrics
        if not _plugin_instance.validate(lambda_adj, phi):
            # Provide critique in the HTTP error message
            from fastapi import HTTPException
            raise HTTPException(status_code=400, detail=_plugin_instance.criticize(lambda_adj, phi))
        # Flatten to Python lists for JSON serialisation
        return ComputeResponse(
            lambda_adj=lambda_adj.detach().cpu().numpy().tolist(),
            phi=phi.detach().cpu().numpy().tolist(),
            omega=omega.detach().cpu().numpy().tolist(),
        )

    @app.get("/history")
    async def history_endpoint() -> list[dict[str, float]]:
        """Return the complete history of computed metrics.

        This endpoint exposes the plugin's trust trace.  Each record
        contains raw inputs, computed metrics and a timestamp.  The
        records are ordered from oldest to newest.
        """
        return _plugin_instance.get_history()

    @app.get("/visualize")
    async def visualize_endpoint() -> dict[str, str]:
        """Visualize the curvature metrics history.

        Generates a simple time‑series plot of Λ_adj, φ and ΩΛ∞
        across the recorded history.  The plot is encoded as a
        base64 PNG string and returned as JSON under the key
        ``"image"``.  If there is no history, a blank plot is
        produced.
        """
        import matplotlib
        matplotlib.use('Agg')  # use non‑interactive backend
        import matplotlib.pyplot as plt
        import base64
        from io import BytesIO

        hist = _plugin_instance.get_history()
        # Prepare data
        if hist:
            timestamps = [h["timestamp"] for h in hist]
            lambda_vals = [h["lambda_adj"] for h in hist]
            phi_vals = [h["phi"] for h in hist]
            omega_vals = [h["omega"] for h in hist]
        else:
            # No history: create zero arrays
            timestamps = [0.0]
            lambda_vals = [0.0]
            phi_vals = [0.0]
            omega_vals = [0.0]

        # Create figure
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.plot(timestamps, lambda_vals, label='Λ_adj', color='tab:blue')
        ax.plot(timestamps, phi_vals, label='φ', color='tab:orange')
        ax.plot(timestamps, omega_vals, label='ΩΛ∞', color='tab:green')
        ax.set_xlabel('Timestamp')
        ax.set_ylabel('Metric Value')
        ax.set_title('Curvature Metrics Over Time')
        ax.legend(loc='best')
        fig.tight_layout()
        # Encode figure to base64
        buf = BytesIO()
        fig.savefig(buf, format='png')
        plt.close(fig)
        buf.seek(0)
        image_base64 = base64.b64encode(buf.read()).decode('ascii')
        return {"image": image_base64}

    def run_api(host: str = "0.0.0.0", port: int = 8000) -> None:
        """Run the FastAPI application using Uvicorn.

        This helper function starts an ASGI server.  It is intended
        for demonstration; in production you might configure
        additional settings such as SSL, logging or workers.
        """
        uvicorn.run(app, host=host, port=port)
except ImportError:
    # FastAPI is optional; if it's not available the API will not
    # be defined.  Users can still import TICEPlugin.
    app = None  # type: ignore
    def run_api(*args, **kwargs) -> None:
        raise RuntimeError("FastAPI is not installed; install fastapi and uvicorn to run the API.")


if __name__ == "__main__":
    # When run as a script, start the REST API if available.
    try:
        print("Starting TICEPlugin API...")
        run_api()
    except RuntimeError as e:
        print(e)